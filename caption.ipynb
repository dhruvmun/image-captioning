{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.4/importlib/_bootstrap.py:321: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, TimeDistributed, Dense, RepeatVector, Merge, Activation, Flatten\n",
    "from keras.preprocessing import image, sequence\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_test = pickle.load(open('encoded_images.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_test['3556792157_d09d42bef7.jpg'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Flickr8k_text/flickr_8k_train_dataset.txt', delimiter='\\t')\n",
    "nb_samples = df.shape[0]\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculating the unique words in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps = []\n",
    "imgs = []\n",
    "iter = df.iterrows()\n",
    "for i in range(nb_samples):\n",
    "    x = next(iter)\n",
    "    caps.append(x[1][1])\n",
    "    imgs.append(x[1][0])\n",
    "\n",
    "len(caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 0\n",
    "for text in caps:\n",
    "    total_samples += len(text.split())-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [txt.split() for txt in caps]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8256"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = list(set(unique))\n",
    "vocab_size = len(unique)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the unique words to indices and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8256"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = {}\n",
    "index_word = {}\n",
    "\n",
    "for i, word in enumerate(unique):\n",
    "    word_index[word]=i\n",
    "    index_word[i]=word\n",
    "    \n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the maximum length among all the captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8256\n",
      "Maximum caption length: 40\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for caption in caps:\n",
    "    if(len(caption.split()) > max_len):\n",
    "        max_len = len(caption.split())\n",
    "\n",
    "print( \"Vocabulary size: \"+str(vocab_size))\n",
    "print( \"Maximum caption length: \"+str(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator \n",
    "\n",
    "We will use the encoding of an image and use a start word to predict the next word.\n",
    "After that, we will again use the same image and use the predicted word \n",
    "to predict the next word.\n",
    "So, the image will be used at every iteration for the entire caption. \n",
    "This is how we will generate the caption for an image. Hence, we need to create \n",
    "a custom generator for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size = 32):\n",
    "    partial_caps = []\n",
    "    next_words = []\n",
    "    images = []\n",
    "    \n",
    "    gen_count = 0\n",
    "    df = pd.read_csv('Flickr8k_text/flickr_8k_train_dataset.txt', delimiter='\\t')\n",
    "    nb_samples = df.shape[0]\n",
    "    iter = df.iterrows()\n",
    "    caps = []\n",
    "    imgs = []\n",
    "    for i in range(nb_samples):\n",
    "        x = next(iter)\n",
    "        caps.append(x[1][1])\n",
    "        imgs.append(x[1][0])\n",
    "\n",
    "\n",
    "        count = 0\n",
    "        while True:\n",
    "            for j, text in enumerate(c):\n",
    "                #print('Image: ',j)\n",
    "                current_image = encoded_images[imgs[j]]\n",
    "                for i in range(len(text.split())-1):\n",
    "                    total_count += 1\n",
    "                    #print('total_count: ', total_count)\n",
    "                    partial = [word_index[txt] for txt in text.split()[:i+1]]\n",
    "                    partial_caps.append(partial)\n",
    "                    n = np.zeros(vocab_size)\n",
    "                    n[word_index[text.split()[i+1]]] = 1\n",
    "                    next_words.append(n)\n",
    "                    images.append(current_image)\n",
    "\n",
    "                    if total_count>=batch_size:\n",
    "                        next_words = np.asarray(next_words)\n",
    "                        images = np.asarray(images)\n",
    "                        partial_caps = sequence.pad_sequences(partial_caps, maxlen=max_len, padding='post')\n",
    "                        total_count = 0\n",
    "                        gen_count+=1\n",
    "                        #print (\"yielding count: \"+str(gen_count))\n",
    "                        yield [[images, partial_caps], next_words]\n",
    "                        partial_caps = []\n",
    "                        next_words = []\n",
    "                        images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "\n",
    "def create_model():\n",
    "\n",
    "    image_model = Sequential()\n",
    "    image_model.add(Dense(EMBEDDING_DIM, input_dim = 4096, activation='relu'))\n",
    "    image_model.add(RepeatVector(max_len))\n",
    "\n",
    "    lang_model = Sequential()\n",
    "    lang_model.add(Embedding(vocab_size, 256, input_length=max_len))\n",
    "    lang_model.add(LSTM(256,return_sequences=True))\n",
    "    lang_model.add(TimeDistributed(Dense(EMBEDDING_DIM)))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Merge([image_model, lang_model], mode='concat'))\n",
    "    model.add(LSTM(1000,return_sequences=False))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel_launcher.py:15: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "merge_3 (Merge)              (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1000)              5028000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8256)              8264256   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8256)              0         \n",
      "=================================================================\n",
      "Total params: 16,488,416\n",
      "Trainable params: 16,488,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "993s - loss: 3.2185 - acc: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/keras/engine/training.py:1573: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76326d5518>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit_generator(data_generator(batch_size=128), samples_per_epoch=samples_per_epoch, nb_epoch=1, \n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('Models/Model.h5', overwrite=True)\n",
    "model.save_weights('Models/Weights.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
